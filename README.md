# FirstNoReapting
### 题目要求

有一个 100GB 的文件，里面内容是文本，要求：找出第一个不重复的词（只允许扫一遍原文件），内存大小32GB。文本数据里均为英文单词，且有换行，空格等常见标点符号，不区分大小写。

### 整体思路

当内存无法全部存下所有数据时，常见思路就是文件分片

- 首先，根据原文件大小和内存大小，适当的分配文件数量和每个文件大小
- 每个分片文件存储的是单词和单词在原文中位置（index），且每个分片文件内按单词字典序排列
- 最后对所有分片文件进行归并排序，读取到index最小的切勿重复的单词就是第一个不重复的词

### 本地测试

本地在MAC上小数据量测试，测试结果ok，还有待进行大数据量测试

### 优化点

因时间问题，暂且实现最简单版本，值得优化的点如下：

1. 文件分片时，可攒到量较大时写入，减少系统调用次数；
2. 且可采用FileChannel配合DirectByteBuffer写入，减少堆内到堆外的拷贝；
3. 目前归并内部仅维护一个单word的数组，每个位置只存当前文件的一个单词。可以增加每次读取量，使每个位置存一个固定大小块，减少系统调用次数；